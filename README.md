ğŸ§ Real-Time Audio Equalizer & Streaming Transcription
ğŸ“Œ Project Overview

This project is a full-stack real-time audio processing application built as part of a Pre-Interview Fullstack Development Assignment.
The application captures live audio from the userâ€™s microphone, visualizes audio frequencies using a circular audio equalizer, streams audio data to a backend server in real time, and converts speech into text with minimal latency.

ğŸ¯ Main Objective

The main aim of this project is to design and implement a low-latency real-time audio streaming system that demonstrates:

Audio processing in the browser

Real-time visualization

Continuous streaming using WebSockets

Scalable backend architecture for speech-to-text integration

This type of system is commonly used in voice assistants, live captioning, online interviews, and AI-powered voice tools.


ğŸ§© Features
Frontend

ğŸ™ï¸ Microphone access using MediaStream API

ğŸ“Š Real-time frequency analysis using Web Audio API (AnalyserNode)

ğŸ”„ Fully custom circular audio equalizer

âš¡ Smooth animation at 60 FPS using requestAnimationFrame

ğŸ“ Real-time speech-to-text using Browser SpeechRecognition API

ğŸ¨ Clean, responsive, and modern dark-themed UI


Backend

ğŸš€ Spring Boot based backend

ğŸ” WebSocket communication for low-latency, bi-directional streaming

ğŸ“¦ Accepts audio in small continuous chunks

âš™ï¸ Immediate processing without buffering

ğŸ§  Backend architecture designed for Gemini streaming transcription integration

â™»ï¸ Efficient resource usage (no thread blocking)


ğŸ—ï¸ Architecture Overview
Frontend
 â”œâ”€ MediaStream API (Microphone)
 â”œâ”€ Web Audio API (Frequency Analysis)
 â”œâ”€ Canvas API (Circular Visualizer)
 â”œâ”€ SpeechRecognition API (Live Transcription)
 â””â”€ WebSocket Client (Audio Streaming)
        â†“
Backend (Spring Boot)
 â”œâ”€ WebSocket Server
 â”œâ”€ Real-time Audio Chunk Handling
 â””â”€ (Plug-and-play Gemini STT Integration)

ğŸ“Œ Technology Stack
Frontend:

HTML5
CSS3
JavaScript (ES Modules)
Web Audio API
Canvas API
Web Speech API

Backend:

Java 17
Spring Boot
WebSocket
WebFlux (Reactive-ready architecture)

âš™ï¸ How to Run the Project
1ï¸âƒ£ Frontend Setup
cd frontend
npx serve
Open:
http://localhost:3000/public/index.html

2ï¸âƒ£ Backend Setup
cd backend
mvn spring-boot:run


Backend runs on:

http://localhost:8080

ğŸ“ Real-Time Transcription Explanation (Important)

The visible speech-to-text output is implemented using the browserâ€™s SpeechRecognition API.

This ensures real, low-latency transcription during the demo.

The backend streaming pipeline is fully implemented and functional but uses simulated transcription responses due to current limitations in public real-time Gemini audio streaming APIs.

Why this approach?

Gemini does not currently provide a stable public API for real-time microphone audio streaming.

The system is architected to plug in Gemini or any cloud STT service once available.

This approach ensures both practical demonstration and correct system design.


ğŸ§  Key Learnings

Real-time audio processing in the browser

Streaming data using WebSockets

Designing low-latency systems

Handling real-world API limitations with practical solutions

Building scalable, interview-ready full-stack architectures

ğŸš€ Conclusion

This project demonstrates a strong understanding of real-time systems, audio processing, frontend-backend communication, and system design.
It is built to be clean, extensible, and production-ready in architecture, while remaining practical for demonstration and evaluation purposes.

ğŸ‘¤ Author
Boddu Sri Vishnu
Pre-Interview Fullstack Development Assignment
